{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/nlp/ipynb/lstm_seq2seq.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tyler\\miniconda3\\envs\\ai-chatbot\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\Tyler\\miniconda3\\envs\\ai-chatbot\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "c:\\Users\\Tyler\\miniconda3\\envs\\ai-chatbot\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\\n%s\" %\n",
      "c:\\Users\\Tyler\\miniconda3\\envs\\ai-chatbot\\lib\\site-packages\\scipy\\__init__.py:143: UserWarning: A NumPy version >=1.19.5 and <1.27.0 is required for this version of SciPy (detected version 1.18.0)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32  # Batch size for training.\n",
    "epochs = 150  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples = 5000  # Number of samples to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open file\n",
    "df = pd.read_csv(\"../data/casual_data_windows.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "df = df.drop([df.columns[0], df.columns[-1]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'0': 'query', '1': 'response'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:num_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What kind of phone(s) do you guys have?</td>\n",
       "      <td>I have a pixel. It's pretty great. Much better...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have a pixel. It's pretty great. Much better...</td>\n",
       "      <td>Does it really charge all the way in 15 min?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Does it really charge all the way in 15 min?</td>\n",
       "      <td>Pretty fast. I've never timed it, but it's und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What kind of phone(s) do you guys have?</td>\n",
       "      <td>Samsung Galaxy J1. It's my first cell phone an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Samsung Galaxy J1. It's my first cell phone an...</td>\n",
       "      <td>What do you think of it? Anything you don't like?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What do you think of it? Anything you don't like?</td>\n",
       "      <td>I love it. I can't think of anything I don't l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What kind of phone(s) do you guys have?</td>\n",
       "      <td>LG Optimus V. I know, it's old.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LG Optimus V. I know, it's old.</td>\n",
       "      <td>If it does it's job, it's good enough!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>My friend told me to kill myself :/</td>\n",
       "      <td>Don't kill yourself OP.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Don't kill yourself OP.</td>\n",
       "      <td>I won't give them the satisfaction ;)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>My friend told me to kill myself :/</td>\n",
       "      <td>Fuck those losers, I'll /we'll be your friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Fuck those losers, I'll /we'll be your friend</td>\n",
       "      <td>Thanks :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I just won a state championship for debate.</td>\n",
       "      <td>No you didn't!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>No you didn't!</td>\n",
       "      <td>Huh?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Huh?</td>\n",
       "      <td>Heh.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>No you didn't!</td>\n",
       "      <td>Huh?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>So I got a girlfriend the other day?</td>\n",
       "      <td>CONGRATS! Hope you are as happy as you could p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CONGRATS! Hope you are as happy as you could p...</td>\n",
       "      <td>Oh I definitely am! I still find myself questi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>So I got a girlfriend the other day?</td>\n",
       "      <td>That's so lovely!! Basically my gay-ass goals.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>That's so lovely!! Basically my gay-ass goals.</td>\n",
       "      <td>Gay ASS GOALS. Double entendres here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>So I got a girlfriend the other day?</td>\n",
       "      <td>so mate, you missed out the important bit, did...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>so mate, you missed out the important bit, did...</td>\n",
       "      <td>Um. Im a girl. Also. Is that your only motivat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Um. Im a girl. Also. Is that your only motivat...</td>\n",
       "      <td>Not my only motivation, but life isnt worth li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Im getting married in an hour.</td>\n",
       "      <td>Good luck. I don't know why you'd need it, but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Good luck. I don't know why you'd need it, but...</td>\n",
       "      <td>To not cry or trip. Haha. Thank you. :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>To not cry or trip. Haha. Thank you. :)</td>\n",
       "      <td>&amp;gt; not cry\\r\\n\\r\\nare you insane\\r\\n\\r\\nyou ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>&amp;gt; not cry\\r\\n\\r\\nare you insane\\r\\n\\r\\nyou ...</td>\n",
       "      <td>In my 6 class textbook (and 7th class extra bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>To not cry or trip. Haha. Thank you. :)</td>\n",
       "      <td>&amp;gt; not cry\\r\\n\\r\\nare you insane\\r\\n\\r\\nyou ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Im getting married in an hour.</td>\n",
       "      <td>seeing as I'm four hours late... HOW'D IT GO??...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>seeing as I'm four hours late... HOW'D IT GO??...</td>\n",
       "      <td>Amazing. It was so much fun. Super easy to do.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Im getting married in an hour.</td>\n",
       "      <td>Enjoy divorce raping your husband and making h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Enjoy divorce raping your husband and making h...</td>\n",
       "      <td>You must be popular.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>You must be popular.</td>\n",
       "      <td>And fun to be aound. Hahha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>And fun to be aound. Hahha</td>\n",
       "      <td>Well, the rest of us hope you had a nice day :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Im getting married in an hour.</td>\n",
       "      <td>Congrats dude! Wish you a amazing life ahead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Congrats dude! Wish you a amazing life ahead</td>\n",
       "      <td>Dude? Did you read the text even?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Dude? Did you read the text even?</td>\n",
       "      <td>Dude is just a term man it's chill bro :P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Dude is just a term man it's chill bro :P</td>\n",
       "      <td>Yes I understand that, you folks don't use dud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Dude is just a term man it's chill bro :P</td>\n",
       "      <td>Yes I understand that, you folks don't use dud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Do you want to talk about something? Even bett...</td>\n",
       "      <td>Do you like any foreign language music?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Do you like any foreign language music?</td>\n",
       "      <td>Hey, I thought you forgot about me. You've ask...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Hey, I thought you forgot about me. You've ask...</td>\n",
       "      <td>My mistake sorry about that no I didn't forget...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>My mistake sorry about that no I didn't forget...</td>\n",
       "      <td>It's not a mistake, just a coincidence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>It's not a mistake, just a coincidence</td>\n",
       "      <td>So how have you been?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>So how have you been?</td>\n",
       "      <td>t the moment I'm fine, how about you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Do you ever have one of those days where every...</td>\n",
       "      <td>One thing that I do to help myself is to write...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>One thing that I do to help myself is to write...</td>\n",
       "      <td>Like in a journal?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Do you ever have one of those days where every...</td>\n",
       "      <td>It happens a lot when I'm tired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>It happens a lot when I'm tired</td>\n",
       "      <td>Yeah that too.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>I had a shitty night. What was the best thing ...</td>\n",
       "      <td>I got an A on a project I was worried about, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                query  \\\n",
       "0             What kind of phone(s) do you guys have?   \n",
       "1   I have a pixel. It's pretty great. Much better...   \n",
       "2        Does it really charge all the way in 15 min?   \n",
       "3             What kind of phone(s) do you guys have?   \n",
       "4   Samsung Galaxy J1. It's my first cell phone an...   \n",
       "5   What do you think of it? Anything you don't like?   \n",
       "6             What kind of phone(s) do you guys have?   \n",
       "7                     LG Optimus V. I know, it's old.   \n",
       "8                 My friend told me to kill myself :/   \n",
       "9                             Don't kill yourself OP.   \n",
       "10                My friend told me to kill myself :/   \n",
       "11     Fuck those losers, I'll /we'll be your friend    \n",
       "12        I just won a state championship for debate.   \n",
       "13                                     No you didn't!   \n",
       "14                                               Huh?   \n",
       "15                                     No you didn't!   \n",
       "16               So I got a girlfriend the other day?   \n",
       "17  CONGRATS! Hope you are as happy as you could p...   \n",
       "18               So I got a girlfriend the other day?   \n",
       "19     That's so lovely!! Basically my gay-ass goals.   \n",
       "20               So I got a girlfriend the other day?   \n",
       "21  so mate, you missed out the important bit, did...   \n",
       "22  Um. Im a girl. Also. Is that your only motivat...   \n",
       "23                     Im getting married in an hour.   \n",
       "24  Good luck. I don't know why you'd need it, but...   \n",
       "25            To not cry or trip. Haha. Thank you. :)   \n",
       "26  &gt; not cry\\r\\n\\r\\nare you insane\\r\\n\\r\\nyou ...   \n",
       "27            To not cry or trip. Haha. Thank you. :)   \n",
       "28                     Im getting married in an hour.   \n",
       "29  seeing as I'm four hours late... HOW'D IT GO??...   \n",
       "30                     Im getting married in an hour.   \n",
       "31  Enjoy divorce raping your husband and making h...   \n",
       "32                              You must be popular.    \n",
       "33                         And fun to be aound. Hahha   \n",
       "34                     Im getting married in an hour.   \n",
       "35      Congrats dude! Wish you a amazing life ahead    \n",
       "36                 Dude? Did you read the text even?    \n",
       "37          Dude is just a term man it's chill bro :P   \n",
       "38          Dude is just a term man it's chill bro :P   \n",
       "39  Do you want to talk about something? Even bett...   \n",
       "40            Do you like any foreign language music?   \n",
       "41  Hey, I thought you forgot about me. You've ask...   \n",
       "42  My mistake sorry about that no I didn't forget...   \n",
       "43             It's not a mistake, just a coincidence   \n",
       "44                              So how have you been?   \n",
       "45  Do you ever have one of those days where every...   \n",
       "46  One thing that I do to help myself is to write...   \n",
       "47  Do you ever have one of those days where every...   \n",
       "48                    It happens a lot when I'm tired   \n",
       "49  I had a shitty night. What was the best thing ...   \n",
       "\n",
       "                                             response  \n",
       "0   I have a pixel. It's pretty great. Much better...  \n",
       "1        Does it really charge all the way in 15 min?  \n",
       "2   Pretty fast. I've never timed it, but it's und...  \n",
       "3   Samsung Galaxy J1. It's my first cell phone an...  \n",
       "4   What do you think of it? Anything you don't like?  \n",
       "5   I love it. I can't think of anything I don't l...  \n",
       "6                     LG Optimus V. I know, it's old.  \n",
       "7              If it does it's job, it's good enough!  \n",
       "8                             Don't kill yourself OP.  \n",
       "9               I won't give them the satisfaction ;)  \n",
       "10     Fuck those losers, I'll /we'll be your friend   \n",
       "11                                          Thanks :)  \n",
       "12                                     No you didn't!  \n",
       "13                                               Huh?  \n",
       "14                                               Heh.  \n",
       "15                                               Huh?  \n",
       "16  CONGRATS! Hope you are as happy as you could p...  \n",
       "17  Oh I definitely am! I still find myself questi...  \n",
       "18     That's so lovely!! Basically my gay-ass goals.  \n",
       "19              Gay ASS GOALS. Double entendres here   \n",
       "20  so mate, you missed out the important bit, did...  \n",
       "21  Um. Im a girl. Also. Is that your only motivat...  \n",
       "22  Not my only motivation, but life isnt worth li...  \n",
       "23  Good luck. I don't know why you'd need it, but...  \n",
       "24            To not cry or trip. Haha. Thank you. :)  \n",
       "25  &gt; not cry\\r\\n\\r\\nare you insane\\r\\n\\r\\nyou ...  \n",
       "26  In my 6 class textbook (and 7th class extra bo...  \n",
       "27  &gt; not cry\\r\\n\\r\\nare you insane\\r\\n\\r\\nyou ...  \n",
       "28  seeing as I'm four hours late... HOW'D IT GO??...  \n",
       "29    Amazing. It was so much fun. Super easy to do.   \n",
       "30  Enjoy divorce raping your husband and making h...  \n",
       "31                              You must be popular.   \n",
       "32                         And fun to be aound. Hahha  \n",
       "33   Well, the rest of us hope you had a nice day :)   \n",
       "34      Congrats dude! Wish you a amazing life ahead   \n",
       "35                 Dude? Did you read the text even?   \n",
       "36          Dude is just a term man it's chill bro :P  \n",
       "37  Yes I understand that, you folks don't use dud...  \n",
       "38  Yes I understand that, you folks don't use dud...  \n",
       "39            Do you like any foreign language music?  \n",
       "40  Hey, I thought you forgot about me. You've ask...  \n",
       "41  My mistake sorry about that no I didn't forget...  \n",
       "42             It's not a mistake, just a coincidence  \n",
       "43                              So how have you been?  \n",
       "44              t the moment I'm fine, how about you?  \n",
       "45  One thing that I do to help myself is to write...  \n",
       "46                                 Like in a journal?  \n",
       "47                    It happens a lot when I'm tired  \n",
       "48                                    Yeah that too.   \n",
       "49  I got an A on a project I was worried about, t...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace({'\\n': ' ', '\\r': ''}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    input_text = row['query']\n",
    "    target_text = row['response']\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    target_text = \"\\t\" + target_text + \"\\n\"\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
    "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
    "encoder = keras.layers.LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "125/125 [==============================] - 111s 888ms/step - loss: 1.7287 - accuracy: 0.6613 - val_loss: 1.6841 - val_accuracy: 0.6273\n",
      "Epoch 2/150\n",
      "125/125 [==============================] - 110s 882ms/step - loss: 1.3953 - accuracy: 0.6682 - val_loss: 1.4268 - val_accuracy: 0.6326\n",
      "Epoch 3/150\n",
      "125/125 [==============================] - 114s 913ms/step - loss: 1.2452 - accuracy: 0.6828 - val_loss: 1.3030 - val_accuracy: 0.6572\n",
      "Epoch 4/150\n",
      "125/125 [==============================] - 118s 943ms/step - loss: 1.1308 - accuracy: 0.7018 - val_loss: 1.2098 - val_accuracy: 0.6737\n",
      "Epoch 5/150\n",
      "125/125 [==============================] - 119s 955ms/step - loss: 1.0577 - accuracy: 0.7154 - val_loss: 1.1646 - val_accuracy: 0.6830\n",
      "Epoch 6/150\n",
      "125/125 [==============================] - 119s 950ms/step - loss: 1.0092 - accuracy: 0.7237 - val_loss: 1.1505 - val_accuracy: 0.6871\n",
      "Epoch 7/150\n",
      "125/125 [==============================] - 117s 933ms/step - loss: 0.9758 - accuracy: 0.7299 - val_loss: 1.1036 - val_accuracy: 0.6981\n",
      "Epoch 8/150\n",
      "125/125 [==============================] - 117s 940ms/step - loss: 0.9556 - accuracy: 0.7355 - val_loss: 1.0745 - val_accuracy: 0.7028\n",
      "Epoch 9/150\n",
      "125/125 [==============================] - 118s 941ms/step - loss: 0.9273 - accuracy: 0.7417 - val_loss: 1.0621 - val_accuracy: 0.7060\n",
      "Epoch 10/150\n",
      "125/125 [==============================] - 117s 937ms/step - loss: 0.9048 - accuracy: 0.7467 - val_loss: 1.0405 - val_accuracy: 0.7132\n",
      "Epoch 11/150\n",
      "125/125 [==============================] - 115s 922ms/step - loss: 0.8828 - accuracy: 0.7526 - val_loss: 1.0217 - val_accuracy: 0.7196\n",
      "Epoch 12/150\n",
      "125/125 [==============================] - 114s 910ms/step - loss: 0.8620 - accuracy: 0.7575 - val_loss: 1.0102 - val_accuracy: 0.7226\n",
      "Epoch 13/150\n",
      "125/125 [==============================] - 113s 908ms/step - loss: 0.8473 - accuracy: 0.7624 - val_loss: 0.9939 - val_accuracy: 0.7261\n",
      "Epoch 14/150\n",
      "125/125 [==============================] - 114s 915ms/step - loss: 0.8272 - accuracy: 0.7661 - val_loss: 0.9819 - val_accuracy: 0.7295\n",
      "Epoch 15/150\n",
      "125/125 [==============================] - 113s 901ms/step - loss: 0.8098 - accuracy: 0.7704 - val_loss: 0.9717 - val_accuracy: 0.7316\n",
      "Epoch 16/150\n",
      "125/125 [==============================] - 113s 904ms/step - loss: 0.7931 - accuracy: 0.7750 - val_loss: 0.9616 - val_accuracy: 0.7340\n",
      "Epoch 17/150\n",
      "125/125 [==============================] - 113s 904ms/step - loss: 0.7775 - accuracy: 0.7789 - val_loss: 0.9572 - val_accuracy: 0.7360\n",
      "Epoch 18/150\n",
      "125/125 [==============================] - 113s 907ms/step - loss: 0.7618 - accuracy: 0.7835 - val_loss: 0.9505 - val_accuracy: 0.7372\n",
      "Epoch 19/150\n",
      "125/125 [==============================] - 113s 908ms/step - loss: 0.7469 - accuracy: 0.7873 - val_loss: 0.9459 - val_accuracy: 0.7387\n",
      "Epoch 20/150\n",
      "125/125 [==============================] - 114s 908ms/step - loss: 0.7338 - accuracy: 0.7913 - val_loss: 0.9394 - val_accuracy: 0.7414\n",
      "Epoch 21/150\n",
      "125/125 [==============================] - 115s 918ms/step - loss: 0.7196 - accuracy: 0.7952 - val_loss: 0.9382 - val_accuracy: 0.7415\n",
      "Epoch 22/150\n",
      "125/125 [==============================] - 114s 912ms/step - loss: 0.7061 - accuracy: 0.7987 - val_loss: 0.9381 - val_accuracy: 0.7424\n",
      "Epoch 23/150\n",
      "125/125 [==============================] - 113s 903ms/step - loss: 0.6923 - accuracy: 0.8024 - val_loss: 0.9403 - val_accuracy: 0.7421\n",
      "Epoch 24/150\n",
      "125/125 [==============================] - 115s 918ms/step - loss: 0.6796 - accuracy: 0.8056 - val_loss: 0.9406 - val_accuracy: 0.7423\n",
      "Epoch 25/150\n",
      "125/125 [==============================] - 113s 907ms/step - loss: 0.6668 - accuracy: 0.8098 - val_loss: 0.9468 - val_accuracy: 0.7419\n",
      "Epoch 26/150\n",
      "125/125 [==============================] - 113s 902ms/step - loss: 0.6539 - accuracy: 0.8131 - val_loss: 0.9428 - val_accuracy: 0.7434\n",
      "Epoch 27/150\n",
      "125/125 [==============================] - 114s 909ms/step - loss: 0.6417 - accuracy: 0.8162 - val_loss: 0.9514 - val_accuracy: 0.7429\n",
      "Epoch 28/150\n",
      "125/125 [==============================] - 114s 910ms/step - loss: 0.6288 - accuracy: 0.8202 - val_loss: 0.9575 - val_accuracy: 0.7407\n",
      "Epoch 29/150\n",
      "125/125 [==============================] - 113s 904ms/step - loss: 0.6167 - accuracy: 0.8238 - val_loss: 0.9664 - val_accuracy: 0.7394\n",
      "Epoch 30/150\n",
      "125/125 [==============================] - 114s 909ms/step - loss: 0.6048 - accuracy: 0.8272 - val_loss: 0.9679 - val_accuracy: 0.7399\n",
      "Epoch 31/150\n",
      "125/125 [==============================] - 113s 908ms/step - loss: 0.5931 - accuracy: 0.8301 - val_loss: 0.9800 - val_accuracy: 0.7387\n",
      "Epoch 32/150\n",
      "125/125 [==============================] - 114s 913ms/step - loss: 0.5816 - accuracy: 0.8338 - val_loss: 0.9820 - val_accuracy: 0.7392\n",
      "Epoch 33/150\n",
      "125/125 [==============================] - 113s 902ms/step - loss: 0.5701 - accuracy: 0.8372 - val_loss: 0.9946 - val_accuracy: 0.7354\n",
      "Epoch 34/150\n",
      "125/125 [==============================] - 117s 933ms/step - loss: 0.5595 - accuracy: 0.8401 - val_loss: 0.9994 - val_accuracy: 0.7372\n",
      "Epoch 35/150\n",
      "125/125 [==============================] - 114s 914ms/step - loss: 0.5491 - accuracy: 0.8431 - val_loss: 1.0075 - val_accuracy: 0.7363\n",
      "Epoch 36/150\n",
      " 11/125 [=>............................] - ETA: 1:27 - loss: 0.5307 - accuracy: 0.8484"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "# Save model\n",
    "model.save(\"s2s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sampling models\n",
    "# Restore the model and construct the encoder and decoder.\n",
    "model = keras.models.load_model(\"s2s\")\n",
    "\n",
    "encoder_inputs = model.input[0]  # input_1\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_inputs = model.input[1]  # input_2\n",
    "decoder_state_input_h = keras.Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = keras.Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_lstm = model.layers[3]\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs\n",
    ")\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "decoder_dense = model.layers[4]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = keras.Model(\n",
    "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
    ")\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: What kind of phone(s) do you guys have?\n",
      "Decoded sentence: I love you don't kind of the mest atdang than somenom :) I cooll bee sliged now..\n",
      "\n",
      "-\n",
      "Input sentence: I have a pixel. It's pretty great. Much better than what I had before. \n",
      "Decoded sentence: I love you don't kind of the mest atdang than somenom :) I cooll bee sliged now..\n",
      "\n",
      "-\n",
      "Input sentence: Does it really charge all the way in 15 min?\n",
      "Decoded sentence: I love you don't kind of the mest atdang than somenom :) I cooll bee sliged now..\n",
      "\n",
      "-\n",
      "Input sentence: What kind of phone(s) do you guys have?\n",
      "Decoded sentence: I love you don't kind of the mest atdang than somenom :) I cooll bee sliged now..\n",
      "\n",
      "-\n",
      "Input sentence: Samsung Galaxy J1. It's my first cell phone and I've had it for 7 months.\n",
      "Decoded sentence: I love you don't kind of the mest atdang than somenom :) I cooll bee sliged now..\n",
      "\n",
      "-\n",
      "Input sentence: What do you think of it? Anything you don't like?\n",
      "Decoded sentence: I love you don't kind of the mest atdang than somenom :) I cooll bee sliged now..\n",
      "\n",
      "-\n",
      "Input sentence: What kind of phone(s) do you guys have?\n",
      "Decoded sentence: I love you don't kind of the mest atdang than somenom :) I cooll bee sliged now..\n",
      "\n",
      "-\n",
      "Input sentence: LG Optimus V. I know, it's old.\n",
      "Decoded sentence: I love you don't kind of the mest atdang than somenom :) I cooll bee sliged now..\n",
      "\n",
      "-\n",
      "Input sentence: My friend told me to kill myself :/\n",
      "Decoded sentence: I love you don't kind of the mest atdang than somenom :) I cooll bee sliged now..\n",
      "\n",
      "-\n",
      "Input sentence: Don't kill yourself OP.\n",
      "Decoded sentence: I love you don't kind of the mest atdang than somenom :) I cooll bee sliged now..\n",
      "\n",
      "-\n",
      "Input sentence: My friend told me to kill myself :/\n",
      "Decoded sentence: I love you don't kind of the mest atdang than somenom :) I cooll bee sliged now..\n",
      "\n",
      "-\n",
      "Input sentence: Fuck those losers, I'll /we'll be your friend \n",
      "Decoded sentence: I love you don't kind of the mest atdang to no I know to know the world you sond I maning soffing mes\n",
      "-\n",
      "Input sentence: I just won a state championship for debate.\n",
      "Decoded sentence: I love you don't kind of the mest atdang to no I know to know the world you sond I maning soffing mes\n",
      "-\n",
      "Input sentence: No you didn't!\n",
      "Decoded sentence: I love you don't kind of the mest atdang than somenom :) I cooll bee sliged now..\n",
      "\n",
      "-\n",
      "Input sentence: Huh?\n",
      "Decoded sentence: I love you don't kind of the mest atdang than somenom :) I hoo do wouk sters will. \n",
      "\n",
      "-\n",
      "Input sentence: No you didn't!\n",
      "Decoded sentence: I love you don't kind of the mest atdang than somenom :) I cooll bee sliged now..\n",
      "\n",
      "-\n",
      "Input sentence: So I got a girlfriend the other day?\n",
      "Decoded sentence: I love you don't kind of the mest atdang than somenom :) I cooll bee sliged now..\n",
      "\n",
      "-\n",
      "Input sentence: CONGRATS! Hope you are as happy as you could possibly be :)\n",
      "Decoded sentence: I love you don't kind of the mest atdang than somenom :) I cooll bee sliged now..\n",
      "\n",
      "-\n",
      "Input sentence: So I got a girlfriend the other day?\n",
      "Decoded sentence: I love you don't kind of the mest atdang than somenom :) I cooll bee sliged now..\n",
      "\n",
      "-\n",
      "Input sentence: That's so lovely!! Basically my gay-ass goals.\n",
      "Decoded sentence: I love you don't kind of the mest atdang than somenom :) I cooll bee sliged now..\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(20):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(\"-\")\n",
    "    print(\"Input sentence:\", input_texts[seq_index])\n",
    "    print(\"Decoded sentence:\", decoded_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
